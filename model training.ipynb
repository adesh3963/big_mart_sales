{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Identifier</th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Fat_Content</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_Type</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Outlet_Identifier</th>\n",
       "      <th>Outlet_Size</th>\n",
       "      <th>Outlet_Location_Type</th>\n",
       "      <th>Outlet_Type</th>\n",
       "      <th>Item_Outlet_Sales</th>\n",
       "      <th>Years_Established</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FDA15</td>\n",
       "      <td>9.30</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>-4.132215</td>\n",
       "      <td>Dairy</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>3735.1380</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DRC01</td>\n",
       "      <td>5.92</td>\n",
       "      <td>Regular Fat</td>\n",
       "      <td>-3.948780</td>\n",
       "      <td>Soft Drinks</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>OUT018</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type2</td>\n",
       "      <td>443.4228</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FDN15</td>\n",
       "      <td>17.50</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>-4.088756</td>\n",
       "      <td>Meat</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>OUT049</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 1</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>2097.2700</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FDX07</td>\n",
       "      <td>19.20</td>\n",
       "      <td>Regular Fat</td>\n",
       "      <td>-4.181625</td>\n",
       "      <td>Fruits and Vegetables</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>OUT010</td>\n",
       "      <td>Medium</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Grocery Store</td>\n",
       "      <td>732.3800</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NCD19</td>\n",
       "      <td>8.93</td>\n",
       "      <td>Low Fat</td>\n",
       "      <td>-4.818097</td>\n",
       "      <td>Household</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>OUT013</td>\n",
       "      <td>High</td>\n",
       "      <td>Tier 3</td>\n",
       "      <td>Supermarket Type1</td>\n",
       "      <td>994.7052</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Item_Identifier  Item_Weight Item_Fat_Content  Item_Visibility  \\\n",
       "0           FDA15         9.30          Low Fat        -4.132215   \n",
       "1           DRC01         5.92      Regular Fat        -3.948780   \n",
       "2           FDN15        17.50          Low Fat        -4.088756   \n",
       "3           FDX07        19.20      Regular Fat        -4.181625   \n",
       "4           NCD19         8.93          Low Fat        -4.818097   \n",
       "\n",
       "               Item_Type  Item_MRP Outlet_Identifier Outlet_Size  \\\n",
       "0                  Dairy  249.8092            OUT049      Medium   \n",
       "1            Soft Drinks   48.2692            OUT018      Medium   \n",
       "2                   Meat  141.6180            OUT049      Medium   \n",
       "3  Fruits and Vegetables  182.0950            OUT010      Medium   \n",
       "4              Household   53.8614            OUT013        High   \n",
       "\n",
       "  Outlet_Location_Type        Outlet_Type  Item_Outlet_Sales  \\\n",
       "0               Tier 1  Supermarket Type1          3735.1380   \n",
       "1               Tier 3  Supermarket Type2           443.4228   \n",
       "2               Tier 1  Supermarket Type1          2097.2700   \n",
       "3               Tier 3      Grocery Store           732.3800   \n",
       "4               Tier 3  Supermarket Type1           994.7052   \n",
       "\n",
       "   Years_Established  \n",
       "0                 22  \n",
       "1                 12  \n",
       "2                 22  \n",
       "3                 23  \n",
       "4                 34  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=data.drop(columns=[\"Item_Identifier\",\"Outlet_Identifier\",\"Item_Outlet_Sales\"])\n",
    "train_vactor=data[\"Item_Outlet_Sales\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.get_dummies(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_Weight</th>\n",
       "      <th>Item_Visibility</th>\n",
       "      <th>Item_MRP</th>\n",
       "      <th>Years_Established</th>\n",
       "      <th>Item_Fat_Content_Low Fat</th>\n",
       "      <th>Item_Fat_Content_Regular Fat</th>\n",
       "      <th>Item_Type_Baking Goods</th>\n",
       "      <th>Item_Type_Breads</th>\n",
       "      <th>Item_Type_Breakfast</th>\n",
       "      <th>Item_Type_Canned</th>\n",
       "      <th>...</th>\n",
       "      <th>Outlet_Size_High</th>\n",
       "      <th>Outlet_Size_Medium</th>\n",
       "      <th>Outlet_Size_Small</th>\n",
       "      <th>Outlet_Location_Type_Tier 1</th>\n",
       "      <th>Outlet_Location_Type_Tier 2</th>\n",
       "      <th>Outlet_Location_Type_Tier 3</th>\n",
       "      <th>Outlet_Type_Grocery Store</th>\n",
       "      <th>Outlet_Type_Supermarket Type1</th>\n",
       "      <th>Outlet_Type_Supermarket Type2</th>\n",
       "      <th>Outlet_Type_Supermarket Type3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.300</td>\n",
       "      <td>-4.132215</td>\n",
       "      <td>249.8092</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.920</td>\n",
       "      <td>-3.948780</td>\n",
       "      <td>48.2692</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17.500</td>\n",
       "      <td>-4.088756</td>\n",
       "      <td>141.6180</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.200</td>\n",
       "      <td>-4.181625</td>\n",
       "      <td>182.0950</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.930</td>\n",
       "      <td>-4.818097</td>\n",
       "      <td>53.8614</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8518</th>\n",
       "      <td>6.865</td>\n",
       "      <td>-2.868511</td>\n",
       "      <td>214.5218</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8519</th>\n",
       "      <td>8.380</td>\n",
       "      <td>-3.057982</td>\n",
       "      <td>108.1570</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8520</th>\n",
       "      <td>10.600</td>\n",
       "      <td>-3.347099</td>\n",
       "      <td>85.1224</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8521</th>\n",
       "      <td>7.210</td>\n",
       "      <td>-1.929501</td>\n",
       "      <td>103.1332</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>14.800</td>\n",
       "      <td>-3.103801</td>\n",
       "      <td>75.4670</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8523 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_Weight  Item_Visibility  Item_MRP  Years_Established  \\\n",
       "0           9.300        -4.132215  249.8092                 22   \n",
       "1           5.920        -3.948780   48.2692                 12   \n",
       "2          17.500        -4.088756  141.6180                 22   \n",
       "3          19.200        -4.181625  182.0950                 23   \n",
       "4           8.930        -4.818097   53.8614                 34   \n",
       "...           ...              ...       ...                ...   \n",
       "8518        6.865        -2.868511  214.5218                 34   \n",
       "8519        8.380        -3.057982  108.1570                 19   \n",
       "8520       10.600        -3.347099   85.1224                 17   \n",
       "8521        7.210        -1.929501  103.1332                 12   \n",
       "8522       14.800        -3.103801   75.4670                 24   \n",
       "\n",
       "      Item_Fat_Content_Low Fat  Item_Fat_Content_Regular Fat  \\\n",
       "0                            1                             0   \n",
       "1                            0                             1   \n",
       "2                            1                             0   \n",
       "3                            0                             1   \n",
       "4                            1                             0   \n",
       "...                        ...                           ...   \n",
       "8518                         1                             0   \n",
       "8519                         0                             1   \n",
       "8520                         1                             0   \n",
       "8521                         0                             1   \n",
       "8522                         1                             0   \n",
       "\n",
       "      Item_Type_Baking Goods  Item_Type_Breads  Item_Type_Breakfast  \\\n",
       "0                          0                 0                    0   \n",
       "1                          0                 0                    0   \n",
       "2                          0                 0                    0   \n",
       "3                          0                 0                    0   \n",
       "4                          0                 0                    0   \n",
       "...                      ...               ...                  ...   \n",
       "8518                       0                 0                    0   \n",
       "8519                       1                 0                    0   \n",
       "8520                       0                 0                    0   \n",
       "8521                       0                 0                    0   \n",
       "8522                       0                 0                    0   \n",
       "\n",
       "      Item_Type_Canned  ...  Outlet_Size_High  Outlet_Size_Medium  \\\n",
       "0                    0  ...                 0                   1   \n",
       "1                    0  ...                 0                   1   \n",
       "2                    0  ...                 0                   1   \n",
       "3                    0  ...                 0                   1   \n",
       "4                    0  ...                 1                   0   \n",
       "...                ...  ...               ...                 ...   \n",
       "8518                 0  ...                 1                   0   \n",
       "8519                 0  ...                 0                   1   \n",
       "8520                 0  ...                 0                   0   \n",
       "8521                 0  ...                 0                   1   \n",
       "8522                 0  ...                 0                   0   \n",
       "\n",
       "      Outlet_Size_Small  Outlet_Location_Type_Tier 1  \\\n",
       "0                     0                            1   \n",
       "1                     0                            0   \n",
       "2                     0                            1   \n",
       "3                     0                            0   \n",
       "4                     0                            0   \n",
       "...                 ...                          ...   \n",
       "8518                  0                            0   \n",
       "8519                  0                            0   \n",
       "8520                  1                            0   \n",
       "8521                  0                            0   \n",
       "8522                  1                            1   \n",
       "\n",
       "      Outlet_Location_Type_Tier 2  Outlet_Location_Type_Tier 3  \\\n",
       "0                               0                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            0   \n",
       "3                               0                            1   \n",
       "4                               0                            1   \n",
       "...                           ...                          ...   \n",
       "8518                            0                            1   \n",
       "8519                            1                            0   \n",
       "8520                            1                            0   \n",
       "8521                            0                            1   \n",
       "8522                            0                            0   \n",
       "\n",
       "      Outlet_Type_Grocery Store  Outlet_Type_Supermarket Type1  \\\n",
       "0                             0                              1   \n",
       "1                             0                              0   \n",
       "2                             0                              1   \n",
       "3                             1                              0   \n",
       "4                             0                              1   \n",
       "...                         ...                            ...   \n",
       "8518                          0                              1   \n",
       "8519                          0                              1   \n",
       "8520                          0                              1   \n",
       "8521                          0                              0   \n",
       "8522                          0                              1   \n",
       "\n",
       "      Outlet_Type_Supermarket Type2  Outlet_Type_Supermarket Type3  \n",
       "0                                 0                              0  \n",
       "1                                 1                              0  \n",
       "2                                 0                              0  \n",
       "3                                 0                              0  \n",
       "4                                 0                              0  \n",
       "...                             ...                            ...  \n",
       "8518                              0                              0  \n",
       "8519                              0                              0  \n",
       "8520                              0                              0  \n",
       "8521                              1                              0  \n",
       "8522                              0                              0  \n",
       "\n",
       "[8523 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test= train_test_split(train_df,train_vactor,test_size=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=20, max_leaf_nodes=20, n_estimators=150)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=RandomForestRegressor(n_estimators=150,max_depth=20,max_leaf_nodes=20)\n",
    "                           \n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6207284382698808"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5915420082458992"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5959718127731783\n"
     ]
    }
   ],
   "source": [
    "acc=cross_val_score(model, X_train, Y_train, cv = 5).mean()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 5, 10, 14], 'min_samples_leaf': [1, 2, 4, 6, 8], 'criterion': ['mse', 'mae'], 'max_leaf_nodes': [5, 10, 15, 20, 25]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4,6,8]\n",
    "#max leaf node\n",
    "max_leaf_nodes=[5,10,15,20,25]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['mse','mae'],\n",
    "              'max_leaf_nodes':max_leaf_nodes}\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 35.8min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 128.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, estimator=RandomForestRegressor(), n_iter=100,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'criterion': ['mse', 'mae'],\n",
       "                                        'max_depth': [10, 120, 230, 340, 450,\n",
       "                                                      560, 670, 780, 890,\n",
       "                                                      1000],\n",
       "                                        'max_features': ['auto', 'sqrt',\n",
       "                                                         'log2'],\n",
       "                                        'max_leaf_nodes': [5, 10, 15, 20, 25],\n",
       "                                        'min_samples_leaf': [1, 2, 4, 6, 8],\n",
       "                                        'min_samples_split': [2, 5, 10, 14],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   random_state=100, verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestRegressor()\n",
    "rf_randomcv=RandomizedSearchCV(estimator=rf,param_distributions=random_grid,n_iter=100,cv=3,verbose=2,\n",
    "                               random_state=100,n_jobs=-1)\n",
    "### fit the randomized model\n",
    "rf_randomcv.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 400,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 8,\n",
       " 'max_leaf_nodes': 15,\n",
       " 'max_features': 'auto',\n",
       " 'max_depth': 450,\n",
       " 'criterion': 'mse'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomcv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_rf_randomcv_model= rf_randomcv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6095797963507774"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_randomcv_model.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5929026286509544"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rf_randomcv_model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "450"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_randomcv.best_params_['max_depth']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': ['mse'], 'max_depth': [450], 'max_features': ['auto'], 'min_samples_leaf': [8, 10, 12], 'min_samples_split': [3, 4, 5, 6, 7], 'n_estimators': [200, 500, 400, 500, 600], 'max_leaf_nodes': [15]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'criterion': [rf_randomcv.best_params_['criterion']],\n",
    "    'max_depth': [rf_randomcv.best_params_['max_depth']],\n",
    "    'max_features': [rf_randomcv.best_params_['max_features']],\n",
    "    'min_samples_leaf': [rf_randomcv.best_params_['min_samples_leaf'], \n",
    "                         rf_randomcv.best_params_['min_samples_leaf']+2, \n",
    "                         rf_randomcv.best_params_['min_samples_leaf'] + 4],\n",
    "    'min_samples_split': [rf_randomcv.best_params_['min_samples_split'] - 2,\n",
    "                          rf_randomcv.best_params_['min_samples_split'] - 1,\n",
    "                          rf_randomcv.best_params_['min_samples_split'], \n",
    "                          rf_randomcv.best_params_['min_samples_split'] +1,\n",
    "                          rf_randomcv.best_params_['min_samples_split'] + 2],\n",
    "    'n_estimators': [rf_randomcv.best_params_['n_estimators'] - 200, rf_randomcv.best_params_['n_estimators'] + 100, \n",
    "                     rf_randomcv.best_params_['n_estimators'], \n",
    "                     rf_randomcv.best_params_['n_estimators'] + 100, rf_randomcv.best_params_['n_estimators'] + 200],\n",
    "    'max_leaf_nodes': [15]\n",
    "}\n",
    "\n",
    "print(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 75 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 225 out of 225 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
       "             param_grid={'criterion': ['mse'], 'max_depth': [450],\n",
       "                         'max_features': ['auto'], 'max_leaf_nodes': [15],\n",
       "                         'min_samples_leaf': [8, 10, 12],\n",
       "                         'min_samples_split': [3, 4, 5, 6, 7],\n",
       "                         'n_estimators': [200, 500, 400, 500, 600]},\n",
       "             verbose=2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Fit the grid_search to the data\n",
    "rf=RandomForestRegressor()\n",
    "grid_search=GridSearchCV(estimator=rf,param_grid=param_grid,cv=3,n_jobs=-1,verbose=2)\n",
    "grid_search.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_grid_model=grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6093803158997985"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_grid_model.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594039641860935\n"
     ]
    }
   ],
   "source": [
    "y_pred=best_grid_model.predict(X_test)\n",
    "r2score= r2_score(Y_test,y_pred)\n",
    "print(r2score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* still did not get the better score,we will try some other hyperparameter techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp,fmin,tpe,STATUS_OK,Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {'criterion': hp.choice('criterion', ['mse', 'mae']),\n",
    "        'max_depth': hp.quniform('max_depth', 400, 1200,50),\n",
    "        'max_features': hp.choice('max_features', ['auto', 'sqrt','log2', None]),\n",
    "        'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
    "        'min_samples_split' : hp.uniform ('min_samples_split', 1, 20),\n",
    "        'n_estimators' : hp.choice('n_estimators', [300, 750, 1200,1300,1500]),\n",
    "        'max_leaf_nodes': hp.choice('max_leaf_nodes',[5,8,15,25,30])  \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'criterion': <hyperopt.pyll.base.Apply at 0x2ad6069a108>,\n",
       " 'max_depth': <hyperopt.pyll.base.Apply at 0x2ad60aac4c8>,\n",
       " 'max_features': <hyperopt.pyll.base.Apply at 0x2ad60aac688>,\n",
       " 'min_samples_leaf': <hyperopt.pyll.base.Apply at 0x2ad60a9a888>,\n",
       " 'min_samples_split': <hyperopt.pyll.base.Apply at 0x2ad60b16848>,\n",
       " 'n_estimators': <hyperopt.pyll.base.Apply at 0x2ad6143fe48>,\n",
       " 'max_leaf_nodes': <hyperopt.pyll.base.Apply at 0x2ad60ab8748>}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt', 'log2'], 'max_depth': [10, 120, 230, 340, 450, 560, 670, 780, 890, 1000], 'min_samples_split': [2, 5, 10, 14], 'min_samples_leaf': [2, 4, 6, 8, 10, 12], 'criterion': ['mse', 'mae'], 'max_leaf_nodes': [2, 4, 8, 12, 15]}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt','log2']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 1000,10)]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10,14]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2,4,6,8,10,12]\n",
    "# Create the random grid\n",
    "param = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "              'criterion':['mse','mae'],\n",
    "              'max_leaf_nodes': [2,4,8,12,15]}\n",
    "print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60847b3c06e40469c2a6dcee1a344bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/1950 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generation 1 - Current best internal CV score: -1176869.4176350986\n",
      "\n",
      "Generation 2 - Current best internal CV score: -1176869.4176350986\n",
      "\n",
      "Generation 3 - Current best internal CV score: -1176869.4176350986\n",
      "\n",
      "Generation 4 - Current best internal CV score: -1176869.4176350986\n",
      "\n",
      "Generation 5 - Current best internal CV score: -1176869.4176350986\n",
      "\n",
      "Generation 6 - Current best internal CV score: -1176869.4176350986\n",
      "\n",
      "Generation 7 - Current best internal CV score: -1176869.4176350986\n",
      "\n",
      "Generation 8 - Current best internal CV score: -1176869.4176350986\n",
      "\n",
      "Generation 9 - Current best internal CV score: -1176869.4176350986\n",
      "\n",
      "Generation 10 - Current best internal CV score: -1176869.4176350986\n",
      "\n",
      "Generation 11 - Current best internal CV score: -1175836.7970849127\n",
      "\n",
      "Generation 12 - Current best internal CV score: -1175836.7970849127\n",
      "\n",
      "Generation 13 - Current best internal CV score: -1175836.7970849127\n",
      "\n",
      "Generation 14 - Current best internal CV score: -1175836.7970849127\n",
      "\n",
      "Generation 15 - Current best internal CV score: -1175836.7970849127\n",
      "\n",
      "Generation 16 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 17 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 18 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 19 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 20 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 21 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 22 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 23 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 24 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 25 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 26 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 27 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "Generation 28 - Current best internal CV score: -1174965.694517363\n",
      "\n",
      "The optimized pipeline was not improved after evaluating 12 more generations. Will end the optimization process.\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\n",
      "Best pipeline: RandomForestRegressor(input_matrix, criterion=mse, max_depth=890, max_features=auto, max_leaf_nodes=15, min_samples_leaf=10, min_samples_split=10, n_estimators=200)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TPOTRegressor(config_dict={'sklearn.ensemble.RandomForestRegressor': {'criterion': ['mse',\n",
       "                                                                                    'mae'],\n",
       "                                                                      'max_depth': [10,\n",
       "                                                                                    120,\n",
       "                                                                                    230,\n",
       "                                                                                    340,\n",
       "                                                                                    450,\n",
       "                                                                                    560,\n",
       "                                                                                    670,\n",
       "                                                                                    780,\n",
       "                                                                                    890,\n",
       "                                                                                    1000],\n",
       "                                                                      'max_features': ['auto',\n",
       "                                                                                       'sqrt',\n",
       "                                                                                       'log2'],\n",
       "                                                                      'max_leaf_nodes': [2,\n",
       "                                                                                         4,\n",
       "                                                                                         8,\n",
       "                                                                                         12,\n",
       "                                                                                         15],\n",
       "                                                                      'min_samples_leaf': [2,\n",
       "                                                                                           4,\n",
       "                                                                                           6,\n",
       "                                                                                           8,\n",
       "                                                                                           10,\n",
       "                                                                                           12],\n",
       "                                                                      'min_samples_split': [2,\n",
       "                                                                                            5,\n",
       "                                                                                            10,\n",
       "                                                                                            14],\n",
       "                                                                      'n_estimators': [200,\n",
       "                                                                                       400,\n",
       "                                                                                       600,\n",
       "                                                                                       800,\n",
       "                                                                                       1000,\n",
       "                                                                                       1200,\n",
       "                                                                                       1400,\n",
       "                                                                                       1600,\n",
       "                                                                                       1800,\n",
       "                                                                                       2000]}},\n",
       "              cv=4, early_stop=12, generations=150, n_jobs=-1,\n",
       "              offspring_size=12, population_size=150, verbosity=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_regressor = TPOTRegressor(generations= 150, population_size= 150, offspring_size= 12,\n",
    "                                 verbosity= 2, early_stop= 12,\n",
    "                                 config_dict={'sklearn.ensemble.RandomForestRegressor': param}, \n",
    "                                 cv = 4,\n",
    "                                 n_jobs=-1)\n",
    "tpot_regressor.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = tpot_regressor.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1189302.3994348177\n"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.586785336372422\n"
     ]
    }
   ],
   "source": [
    "y_pred=tpot_regressor.predict(X_test)\n",
    "print(r2_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "after this many attempts i am anable to improve the r2_score much further"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### choosing the tunning parameter of rendomized search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model=RandomForestRegressor(n_estimators= 400,\n",
    "     min_samples_split= 5,\n",
    "     min_samples_leaf= 8,\n",
    "     max_leaf_nodes= 15,\n",
    "     max_features= 'auto',\n",
    "     max_depth=450,\n",
    "     criterion ='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=450, max_leaf_nodes=15, min_samples_leaf=8,\n",
       "                      min_samples_split=5, n_estimators=400)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6111283951535258"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.score(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5905706912872344"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5905706912872344\n"
     ]
    }
   ],
   "source": [
    "y_pred=final_model.predict(X_test)\n",
    "print(r2_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5971307706043495\n"
     ]
    }
   ],
   "source": [
    "acc=cross_val_score(final_model, X_train, Y_train, cv = 5).mean()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.42% (2.77%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "kfold = KFold(n_splits=10, random_state=7)\n",
    "results = cross_val_score(final_model,train_df,train_vactor, cv=kfold)\n",
    "print(\"score: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the overall accuracy we get is around 60%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'finalized_model.pkl'\n",
    "pickle.dump(final_model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5905706912872344\n"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model saved successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training with neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras_tuner.tuners import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0', '/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
      "units_0 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "units_1 (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu Available:  1\n"
     ]
    }
   ],
   "source": [
    "pd=tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"gpu Available: \",len(pd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "train_df=scaler.fit_transform(train_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test= train_test_split(train_df,train_vactor,test_size=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    for i in range(hp.Int('num_layers', 2, 20)):\n",
    "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                            min_value=32,\n",
    "                                            max_value=512,\n",
    "                                            step=32),\n",
    "                               activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(\n",
    "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "        loss='mean_absolute_error',\n",
    "        metrics=['mean_absolute_error'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_mean_absolute_error',\n",
    "    max_trials=3,\n",
    "    executions_per_trial=2,\n",
    "    directory='project',\n",
    "    project_name='bigmart_sale_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 3 Complete [00h 02m 45s]\n",
      "val_mean_absolute_error: 748.2380065917969\n",
      "\n",
      "Best val_mean_absolute_error So Far: 745.1890258789062\n",
      "Total elapsed time: 00h 06m 37s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(x_train, y_train,\n",
    "             epochs=50,\n",
    "             validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in project\\bigmart_sale_2\n",
      "Showing 10 best trials\n",
      "Objective(name='val_mean_absolute_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 9\n",
      "units_0: 224\n",
      "units_1: 160\n",
      "learning_rate: 0.001\n",
      "units_2: 288\n",
      "units_3: 96\n",
      "units_4: 288\n",
      "units_5: 288\n",
      "units_6: 384\n",
      "units_7: 128\n",
      "units_8: 32\n",
      "Score: 745.1890258789062\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 8\n",
      "units_0: 224\n",
      "units_1: 480\n",
      "learning_rate: 0.01\n",
      "units_2: 32\n",
      "units_3: 32\n",
      "units_4: 32\n",
      "units_5: 32\n",
      "units_6: 32\n",
      "units_7: 32\n",
      "Score: 747.4644470214844\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "num_layers: 16\n",
      "units_0: 64\n",
      "units_1: 512\n",
      "learning_rate: 0.0001\n",
      "units_2: 512\n",
      "units_3: 288\n",
      "units_4: 416\n",
      "units_5: 224\n",
      "units_6: 128\n",
      "units_7: 256\n",
      "units_8: 64\n",
      "units_9: 32\n",
      "units_10: 32\n",
      "units_11: 32\n",
      "units_12: 32\n",
      "units_13: 32\n",
      "units_14: 32\n",
      "units_15: 32\n",
      "Score: 748.2380065917969\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LeakyReLU,PReLU,ELU\n",
    "from keras.layers import Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "\n",
    "# Adding the input layer and the first hidden layer\n",
    "reg.add(Dense(224, kernel_initializer= 'he_uniform',activation='relu',input_shape=(32,)))\n",
    "reg.add(Dropout(0.2))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "reg.add(Dense(160,kernel_initializer= 'he_uniform' ,activation='relu'))\n",
    "\n",
    "reg.add(Dense(288,kernel_initializer= 'he_uniform' ,activation='relu'))\n",
    "reg.add(Dense(96,kernel_initializer= 'he_uniform' ,activation='relu'))\n",
    "\n",
    "reg.add(Dense(288,kernel_initializer= 'he_uniform' ,activation='relu'))\n",
    "reg.add(Dense(288,kernel_initializer= 'he_uniform' ,activation='relu'))\n",
    "reg.add(Dense(384,kernel_initializer= 'he_uniform' ,activation='relu'))\n",
    "reg.add(Dense(128,kernel_initializer= 'he_uniform' ,activation='relu'))\n",
    "reg.add(Dense(32,kernel_initializer= 'he_uniform' ,activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "                     \n",
    "                     \n",
    "                     \n",
    "# Adding the output layer\n",
    "reg.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compiling the ANN\n",
    "reg.compile(optimizer = keras.optimizers.Adam(learning_rate=0.001), loss = 'mean_absolute_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "# Fitting the ANN to the Training set\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1364/1364 [==============================] - 8s 6ms/step - loss: 750.0978 - mean_absolute_error: 750.0978 - val_loss: 783.6254 - val_mean_absolute_error: 783.6255\n",
      "Epoch 2/10\n",
      "1364/1364 [==============================] - 8s 6ms/step - loss: 748.6844 - mean_absolute_error: 748.6844 - val_loss: 785.6794 - val_mean_absolute_error: 785.6794\n",
      "Epoch 3/10\n",
      "1364/1364 [==============================] - 8s 6ms/step - loss: 749.3286 - mean_absolute_error: 749.3286 - val_loss: 789.3117 - val_mean_absolute_error: 789.3117\n",
      "Epoch 4/10\n",
      "1364/1364 [==============================] - 8s 6ms/step - loss: 741.8735 - mean_absolute_error: 741.8735 - val_loss: 809.1155 - val_mean_absolute_error: 809.1155\n",
      "Epoch 5/10\n",
      "1364/1364 [==============================] - 8s 6ms/step - loss: 750.8520 - mean_absolute_error: 750.8520 - val_loss: 828.7867 - val_mean_absolute_error: 828.7867\n",
      "Epoch 6/10\n",
      "1364/1364 [==============================] - 8s 6ms/step - loss: 747.1757 - mean_absolute_error: 747.1757 - val_loss: 860.2438 - val_mean_absolute_error: 860.2438\n",
      "Epoch 7/10\n",
      "1364/1364 [==============================] - 9s 6ms/step - loss: 750.8456 - mean_absolute_error: 750.8456 - val_loss: 817.5270 - val_mean_absolute_error: 817.5270\n",
      "Epoch 8/10\n",
      "1364/1364 [==============================] - 9s 6ms/step - loss: 747.4345 - mean_absolute_error: 747.4345 - val_loss: 782.9922 - val_mean_absolute_error: 782.9922\n",
      "Epoch 9/10\n",
      "1364/1364 [==============================] - 9s 6ms/step - loss: 746.9542 - mean_absolute_error: 746.9542 - val_loss: 798.7103 - val_mean_absolute_error: 798.7103\n",
      "Epoch 10/10\n",
      "1364/1364 [==============================] - 9s 6ms/step - loss: 739.5677 - mean_absolute_error: 739.5677 - val_loss: 809.8368 - val_mean_absolute_error: 809.8368\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x284be051a08>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train, y_train,batch_size = 5, epochs = 10, validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5091821725969783\n",
      "1467928.6310341707\n"
     ]
    }
   ],
   "source": [
    "ypred=reg.predict(x_test)\n",
    "print(r2_score(y_test,ypred))\n",
    "print(mean_squared_error (y_test,ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
